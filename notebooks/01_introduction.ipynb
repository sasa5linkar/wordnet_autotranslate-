{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet Auto-Translation Introduction\n",
    "\n",
    "This notebook provides an introduction to the WordNet Auto-Translation system using DSPy pipelines.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The WordNet Auto-Translation project aims to expand WordNet coverage for less-resourced languages by:\n",
    "- Using DSPy for optimized translation pipelines\n",
    "- Leveraging precision words and examples from target languages\n",
    "- Providing tools for automatic synset translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from wordnet_autotranslate import TranslationPipeline, SynsetHandler, LanguageUtils\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the Translation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize translation pipeline for Spanish\n",
    "pipeline = TranslationPipeline(source_lang='en', target_lang='spanish')\n",
    "\n",
    "print(f\"Pipeline configured for: {LanguageUtils.get_language_name('en')} -> {LanguageUtils.get_language_name('es')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spanish examples\n",
    "examples = pipeline.load_examples()\n",
    "\n",
    "print(f\"Loaded {len(examples['words'])} words and {len(examples['sentences'])} sentences\")\n",
    "print(\"\\nSample words:\")\n",
    "for word in examples['words'][:5]:\n",
    "    print(f\"  - {word}\")\n",
    "    \n",
    "print(\"\\nSample sentences:\")\n",
    "for sentence in examples['sentences'][:3]:\n",
    "    print(f\"  - {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with WordNet Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize synset handler\n",
    "synset_handler = SynsetHandler()\n",
    "\n",
    "# Get synsets for a word\n",
    "word = \"dog\"\n",
    "synsets = synset_handler.get_synsets(word)\n",
    "\n",
    "print(f\"Found {len(synsets)} synsets for '{word}':\")\n",
    "for i, synset in enumerate(synsets[:3]):  # Show first 3\n",
    "    print(f\"\\n{i+1}. {synset['name']}\")\n",
    "    print(f\"   Definition: {synset['definition']}\")\n",
    "    print(f\"   Examples: {synset['examples']}\")\n",
    "    print(f\"   Lemmas: {synset['lemmas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Language Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze available languages\n",
    "from pathlib import Path\n",
    "\n",
    "examples_path = Path('../examples')\n",
    "available_languages = LanguageUtils.get_available_languages(examples_path)\n",
    "\n",
    "print(\"Available languages:\")\n",
    "for lang in available_languages:\n",
    "    validation = LanguageUtils.validate_examples_directory(examples_path, lang)\n",
    "    status = \"✓\" if validation['has_content'] else \"⚠\"\n",
    "    print(f\"  {status} {lang} ({LanguageUtils.get_language_name(lang)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sample text\n",
    "sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "cleaned_text = LanguageUtils.clean_text(sample_text)\n",
    "words = LanguageUtils.extract_words(sample_text)\n",
    "stopwords = LanguageUtils.load_stopwords('en')\n",
    "\n",
    "# Filter out stopwords\n",
    "content_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Cleaned: {cleaned_text}\")\n",
    "print(f\"All words: {words}\")\n",
    "print(f\"Content words: {content_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple visualization of language coverage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data for visualization\n",
    "languages = ['Spanish', 'French', 'German', 'Portuguese']\n",
    "word_counts = [10, 10, 0, 0]  # Based on our examples\n",
    "sentence_counts = [10, 10, 0, 0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Words chart\n",
    "ax1.bar(languages, word_counts, color='skyblue')\n",
    "ax1.set_title('Precision Words by Language')\n",
    "ax1.set_ylabel('Number of Words')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Sentences chart\n",
    "ax2.bar(languages, sentence_counts, color='lightgreen')\n",
    "ax2.set_title('Example Sentences by Language')\n",
    "ax2.set_ylabel('Number of Sentences')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Add more language examples**: Contribute precision words and sentences for additional languages\n",
    "2. **Implement DSPy pipeline**: Develop the actual translation logic using DSPy\n",
    "3. **Train models**: Use the examples to fine-tune translation models\n",
    "4. **Evaluate results**: Create benchmarks for translation quality\n",
    "\n",
    "See the other notebooks for more advanced topics:\n",
    "- `02_translation_pipeline.ipynb`: Detailed pipeline implementation\n",
    "- `03_language_expansion.ipynb`: Adding new languages\n",
    "- `04_evaluation.ipynb`: Quality assessment and metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
