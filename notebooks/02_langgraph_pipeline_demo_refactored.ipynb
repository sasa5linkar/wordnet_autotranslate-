{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64539ac",
   "metadata": {},
   "source": [
    "# LangGraph Translation Pipeline - Comprehensive Demo\n",
    "\n",
    "This notebook demonstrates the **multi-stage translation pipeline** with all new features:\n",
    "\n",
    "## Pipeline Stages:\n",
    "1. **Sense Analysis** - Understand semantic nuances and context\n",
    "2. **Definition Translation** - Translate definition with cultural adaptation\n",
    "3. **Initial Translation** - Direct translation of each lemma\n",
    "4. **Synonym Expansion** - Iteratively broaden candidate pool (NEW: up to 5 iterations)\n",
    "5. **Synonym Filtering** - Quality check with per-word confidence (NEW: definition-anchored validation)\n",
    "6. **Result Assembly** - Combine outputs into final synset\n",
    "\n",
    "## New Features Demonstrated:\n",
    "- ‚ú® **Iterative Expansion**: Runs expansion multiple times until convergence\n",
    "- ‚ú® **Definition-Anchored Filtering**: Validates synonyms against translated definition\n",
    "- ‚ú® **Per-Word Confidence**: Individual quality scores for each synonym\n",
    "- ‚ú® **Full Log Access**: Untruncated LLM outputs for analysis\n",
    "- ‚ú® **Definition Comparison**: Compare translated definitions with existing Serbian glosses\n",
    "- ‚ú® **Serbian WordNet Comparison**: Compare with existing human translations\n",
    "\n",
    "## Why Definitions Matter:\n",
    "üìñ **Definitions are the foundation of WordNet structure**\n",
    "- They define semantic boundaries of each synset\n",
    "- They determine which synonyms belong together\n",
    "- They enable precise cross-lingual alignment\n",
    "- Matching definitions = same concept, even with different synonym choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd5cf9",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcbe662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import json\n",
    "import importlib\n",
    "import ollama\n",
    "import wordnet_autotranslate.pipelines.langgraph_translation_pipeline as lg_module\n",
    "\n",
    "# Reload module to get latest changes\n",
    "lg_module = importlib.reload(lg_module)\n",
    "LangGraphTranslationPipeline = lg_module.LangGraphTranslationPipeline\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6117bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 27 English-Serbian synset pairs\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "DATA_PATH = Path(\"../examples/serbian_english_synset_pairs_enhanced.json\")\n",
    "with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "pairs = dataset[\"pairs\"]\n",
    "print(f\"‚úÖ Loaded {len(pairs)} English-Serbian synset pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd22358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using model: gpt-oss:120b\n"
     ]
    }
   ],
   "source": [
    "# Configure Ollama\n",
    "PREFERRED_MODEL = \"gpt-oss:120b\"\n",
    "TIMEOUT = 180\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# Check available models\n",
    "model_list = ollama.list()\n",
    "available = {m.model for m in model_list.models}\n",
    "\n",
    "if PREFERRED_MODEL in available:\n",
    "    model = PREFERRED_MODEL\n",
    "else:\n",
    "    model = sorted(available)[0]\n",
    "    print(f\"‚ö†Ô∏è  Preferred model '{PREFERRED_MODEL}' not found, using '{model}'\")\n",
    "\n",
    "print(f\"‚úÖ Using model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a32317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline initialized\n",
      "   Max expansion iterations: 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline with iterative expansion\n",
    "pipeline = LangGraphTranslationPipeline(\n",
    "    source_lang=\"en\",\n",
    "    target_lang=\"sr\",\n",
    "    model=model,\n",
    "    temperature=TEMPERATURE,\n",
    "    timeout=TIMEOUT,\n",
    "    max_expansion_iterations=5  # NEW: Iterative expansion\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pipeline initialized\")\n",
    "print(f\"   Max expansion iterations: {pipeline.max_expansion_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89970d",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Detailed Translation Example\n",
    "\n",
    "Let's translate the first synset and examine each stage in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a863de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Synset to translate:\n",
      "   ID: ENG30-03574555-n\n",
      "   Lemmas: institution\n",
      "   Definition: an establishment consisting of a building or complex of buildings where an organization for the promotion of some cause is situated\n",
      "   POS: n\n"
     ]
    }
   ],
   "source": [
    "# Prepare first synset\n",
    "pair_0 = pairs[0]\n",
    "synset_0 = {\n",
    "    \"id\": pair_0[\"english_id\"],\n",
    "    \"lemmas\": pair_0[\"english_lemmas\"],\n",
    "    \"definition\": pair_0[\"english_definition\"],\n",
    "    \"examples\": pair_0.get(\"english_examples\", []),\n",
    "    \"pos\": pair_0[\"english_pos\"],\n",
    "}\n",
    "\n",
    "print(\"üìã Synset to translate:\")\n",
    "print(f\"   ID: {synset_0['id']}\")\n",
    "print(f\"   Lemmas: {', '.join(synset_0['lemmas'])}\")\n",
    "print(f\"   Definition: {synset_0['definition']}\")\n",
    "print(f\"   POS: {synset_0['pos']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467479b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running translation pipeline...\n",
      "\n",
      "[Expansion] Iteration 1: Added 6 new synonym(s), total: 7\n",
      "[Expansion] Iteration 1: Added 6 new synonym(s), total: 7\n",
      "[Expansion] Iteration 2: Added 3 new synonym(s), total: 10\n",
      "[Expansion] Iteration 2: Added 3 new synonym(s), total: 10\n",
      "[Expansion] Iteration 3: Added 3 new synonym(s), total: 13\n",
      "[Expansion] Iteration 3: Added 3 new synonym(s), total: 13\n",
      "[Expansion] Converged after 4 iteration(s) - no new synonyms found\n",
      "[Expansion] Converged after 4 iteration(s) - no new synonyms found\n",
      "[Filter] Flagged potential compounds: ['glavno sedi≈°te', 'glavni ured', 'upravno sedi≈°te']\n",
      "‚úÖ Translation complete!\n",
      "[Filter] Flagged potential compounds: ['glavno sedi≈°te', 'glavni ured', 'upravno sedi≈°te']\n",
      "‚úÖ Translation complete!\n"
     ]
    }
   ],
   "source": [
    "# Run translation (this takes ~5-10 minutes with iterative expansion)\n",
    "print(\"üîÑ Running translation pipeline...\\n\")\n",
    "result_0 = pipeline.translate_synset(synset_0)\n",
    "print(\"‚úÖ Translation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d4ae4",
   "metadata": {},
   "source": [
    "### Stage-by-Stage Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 1: SENSE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Sense summary: A physical establishment‚Äîusually a single building or a complex of buildings‚Äîthat serves as the headquarters or venue for an organization dedicated to promoting a particular cause.\n",
      "Confidence: high\n",
      "\n",
      "================================================================================\n",
      "STAGE 2: DEFINITION TRANSLATION\n",
      "================================================================================\n",
      "\n",
      "üá¨üáß English: an establishment consisting of a building or complex of buildings where an organization for the promotion of some cause is situated\n",
      "üá∑üá∏ Serbian: zgrada ili kompleks zgrada u kome je sme≈°tena organizacija posveƒáena promovisanja odreƒëenog cilja\n",
      "\n",
      "================================================================================\n",
      "STAGE 3: INITIAL TRANSLATION\n",
      "================================================================================\n",
      "\n",
      "Translated 1 lemmas:\n",
      "  1. sedi≈°te\n",
      "\n",
      "================================================================================\n",
      "STAGE 4: ITERATIVE EXPANSION\n",
      "================================================================================\n",
      "\n",
      "üîÑ Iterations: 4\n",
      "‚úì Converged: Yes\n",
      "üìä Total synonyms: 13\n",
      "\n",
      "Expanded synonyms: administrativni centar, baza, centralna kancelarija, centralni objekat, glavna kancelarija, glavna lokacija, glavni ured, glavno sedi≈°te, kancelarija, sedi≈°te, sedi≈°te organizacije, upravno sedi≈°te, ured\n",
      "\n",
      "üìà Synonyms by iteration:\n",
      "   Initial: 1 synonyms\n",
      "   Iteration 1: 6 new synonyms\n",
      "   Iteration 2: 3 new synonyms\n",
      "   Iteration 3: 3 new synonyms\n",
      "\n",
      "================================================================================\n",
      "STAGE 5: FILTERING\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Kept: 6 synonyms\n",
      "‚ùå Removed: 6 candidates\n",
      "\n",
      "Final synonyms: sedi≈°te, glavno sedi≈°te, administrativni centar, glavni ured, centralna kancelarija, upravno sedi≈°te\n",
      "\n",
      "üéØ Per-word confidence:\n",
      "   üü¢ sedi≈°te              ‚Üí high\n",
      "   üü¢ glavno sedi≈°te       ‚Üí high\n",
      "   üü¢ administrativni centar ‚Üí high\n",
      "   üü¢ glavni ured          ‚Üí high\n",
      "   üü° centralna kancelarija ‚Üí medium\n",
      "   üü° upravno sedi≈°te      ‚Üí medium\n",
      "\n",
      "‚ùå Removed candidates:\n",
      "   ‚Ä¢ baza                 ‚Üí different concept (military/base connotation), not idiomatic for organizational headquarters\n",
      "   ‚Ä¢ centralni objekat    ‚Üí unnatural and vague in Serbian for a headquarters\n",
      "   ‚Ä¢ glavna lokacija      ‚Üí less idiomatic; can refer to any main site, not specifically a headquarters\n",
      "   ‚Ä¢ kancelarija          ‚Üí generic term for an office, not specifically a headquarters\n",
      "   ‚Ä¢ ured                 ‚Üí generic term for a room/office, not appropriate for the concept of headquarters\n",
      "   ‚Ä¢ sedi≈°te organizacije ‚Üí redundant phrase; the base term \"sedi≈°te\" already covers the meaning\n"
     ]
    }
   ],
   "source": [
    "# Extract stage payloads\n",
    "payload_0 = result_0[\"payload\"]\n",
    "sense_0 = payload_0[\"sense\"]\n",
    "definition_0 = payload_0[\"definition\"]\n",
    "initial_0 = payload_0[\"initial_translation\"]\n",
    "expansion_0 = payload_0[\"expansion\"]\n",
    "filtering_0 = payload_0[\"filtering\"]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STAGE 1: SENSE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSense summary: {sense_0['sense_summary']}\")\n",
    "print(f\"Confidence: {sense_0.get('confidence', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STAGE 2: DEFINITION TRANSLATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüá¨üáß English definition:\")\n",
    "print(f\"   {synset_0['definition']}\")\n",
    "print(f\"\\nüá∑üá∏ Serbian translation (from pipeline):\")\n",
    "print(f\"   {definition_0['definition_translation']}\")\n",
    "print(f\"\\nüìö Existing Serbian gloss (from WordNet):\")\n",
    "print(f\"   {pair_0['serbian_definition']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STAGE 3: INITIAL TRANSLATION\")\n",
    "print(\"=\" * 80)\n",
    "translations = initial_0['initial_translations']\n",
    "print(f\"\\nTranslated {len(translations)} lemmas:\")\n",
    "for i, trans in enumerate(translations, 1):\n",
    "    print(f\"  {i}. {trans}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STAGE 4: ITERATIVE EXPANSION\")\n",
    "print(\"=\" * 80)\n",
    "expanded = expansion_0['expanded_synonyms']\n",
    "iterations = expansion_0.get('iterations_run', 1)\n",
    "converged = expansion_0.get('converged', False)\n",
    "print(f\"\\nüîÑ Iterations: {iterations}\")\n",
    "print(f\"‚úì Converged: {'Yes' if converged else 'No (hit max limit)'}\")\n",
    "print(f\"üìä Total synonyms: {len(expanded)}\")\n",
    "print(f\"\\nExpanded synonyms: {', '.join(expanded)}\")\n",
    "\n",
    "# Show synonym provenance\n",
    "provenance = expansion_0.get('synonym_provenance', {})\n",
    "if provenance:\n",
    "    iter_counts = {}\n",
    "    for syn, iter_num in provenance.items():\n",
    "        iter_counts[iter_num] = iter_counts.get(iter_num, 0) + 1\n",
    "    \n",
    "    print(f\"\\nüìà Synonyms by iteration:\")\n",
    "    for iter_num in sorted(iter_counts.keys()):\n",
    "        count = iter_counts[iter_num]\n",
    "        if iter_num == 0:\n",
    "            print(f\"   Initial: {count} synonyms\")\n",
    "        else:\n",
    "            print(f\"   Iteration {iter_num}: {count} new synonyms\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STAGE 5: FILTERING\")\n",
    "print(\"=\" * 80)\n",
    "filtered = filtering_0['filtered_synonyms']\n",
    "removed_items = filtering_0.get('removed', [])\n",
    "confidence_by_word = filtering_0.get('confidence_by_word', {})\n",
    "\n",
    "print(f\"\\n‚úÖ Kept: {len(filtered)} synonyms\")\n",
    "print(f\"‚ùå Removed: {len(removed_items)} candidates\")\n",
    "print(f\"\\nFinal synonyms: {', '.join(filtered)}\")\n",
    "\n",
    "if confidence_by_word:\n",
    "    print(f\"\\nüéØ Per-word confidence:\")\n",
    "    for word, conf in confidence_by_word.items():\n",
    "        emoji = \"üü¢\" if conf == \"high\" else \"üü°\" if conf == \"medium\" else \"üî¥\"\n",
    "        print(f\"   {emoji} {word:20} ‚Üí {conf}\")\n",
    "\n",
    "if removed_items:\n",
    "    print(f\"\\n‚ùå Removed candidates:\")\n",
    "    for item in removed_items:\n",
    "        word = item.get('word', '?')\n",
    "        reason = item.get('reason', 'No reason')\n",
    "        print(f\"   ‚Ä¢ {word:20} ‚Üí {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f89f21",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Batch Translation\n",
    "\n",
    "Now let's translate 4 more synsets to see how the pipeline handles different types of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaaeaec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ENG30-07810907-n (n)\n",
      "   Lemmas: condiment\n",
      "   Definition: a preparation (a sauce or relish or spice) to enhance flavor...\n",
      "\n",
      "2. ENG30-01376245-v (v)\n",
      "   Lemmas: scatter, sprinkle\n",
      "   Definition: distribute loosely...\n",
      "\n",
      "3. ENG30-01382083-v (v)\n",
      "   Lemmas: pick, pluck\n",
      "   Definition: look for and gather...\n",
      "\n",
      "4. ENG30-01393996-v (v)\n",
      "   Lemmas: sweep\n",
      "   Definition: clean by sweeping...\n",
      "\n",
      "‚úÖ Prepared 4 synsets for translation\n"
     ]
    }
   ],
   "source": [
    "# Prepare synsets 1-4\n",
    "synsets_1_4 = []\n",
    "for i in range(1, 5):\n",
    "    pair = pairs[i]\n",
    "    synset = {\n",
    "        \"id\": pair[\"english_id\"],\n",
    "        \"lemmas\": pair[\"english_lemmas\"],\n",
    "        \"definition\": pair[\"english_definition\"],\n",
    "        \"examples\": pair.get(\"english_examples\", []),\n",
    "        \"pos\": pair[\"english_pos\"],\n",
    "    }\n",
    "    synsets_1_4.append(synset)\n",
    "    \n",
    "    print(f\"{i}. {synset['id']} ({synset['pos']})\")\n",
    "    print(f\"   Lemmas: {', '.join(synset['lemmas'][:2])}\")\n",
    "    print(f\"   Definition: {synset['definition'][:60]}...\\n\")\n",
    "\n",
    "print(f\"‚úÖ Prepared {len(synsets_1_4)} synsets for translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc7a063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Translating 4 synsets...\n",
      "\n",
      "[1/4] Translating ENG30-07810907-n...\n",
      "[Expansion] Iteration 1: Added 3 new synonym(s), total: 4\n",
      "[Expansion] Iteration 1: Added 3 new synonym(s), total: 4\n",
      "[Expansion] Iteration 2: Added 1 new synonym(s), total: 5\n",
      "[Expansion] Iteration 2: Added 1 new synonym(s), total: 5\n",
      "[Expansion] Iteration 3: Added 2 new synonym(s), total: 7\n",
      "[Expansion] Iteration 3: Added 2 new synonym(s), total: 7\n",
      "[Expansion] Iteration 4: Added 3 new synonym(s), total: 10\n",
      "[Expansion] Iteration 4: Added 3 new synonym(s), total: 10\n",
      "[Expansion] Converged after 5 iteration(s) - no new synonyms found\n",
      "[Expansion] Converged after 5 iteration(s) - no new synonyms found\n",
      "   ‚úÖ 6 synonyms, confidence: high\n",
      "\n",
      "[2/4] Translating ENG30-01376245-v...\n",
      "   ‚úÖ 6 synonyms, confidence: high\n",
      "\n",
      "[2/4] Translating ENG30-01376245-v...\n",
      "[Expansion] Iteration 1: Added 5 new synonym(s), total: 9\n",
      "[Expansion] Iteration 1: Added 5 new synonym(s), total: 9\n",
      "[Expansion] Iteration 2: Added 2 new synonym(s), total: 11\n",
      "[Expansion] Iteration 2: Added 2 new synonym(s), total: 11\n",
      "[Expansion] Iteration 3: Added 2 new synonym(s), total: 13\n",
      "[Expansion] Iteration 3: Added 2 new synonym(s), total: 13\n",
      "[Expansion] Iteration 4: Added 2 new synonym(s), total: 15\n",
      "[Expansion] Iteration 4: Added 2 new synonym(s), total: 15\n",
      "[Expansion] Converged after 5 iteration(s) - no new synonyms found\n",
      "[Expansion] Converged after 5 iteration(s) - no new synonyms found\n",
      "   ‚úÖ 7 synonyms, confidence: high\n",
      "\n",
      "[3/4] Translating ENG30-01382083-v...\n",
      "   ‚úÖ 7 synonyms, confidence: high\n",
      "\n",
      "[3/4] Translating ENG30-01382083-v...\n",
      "[Expansion] Iteration 1: Added 3 new synonym(s), total: 6\n",
      "[Expansion] Iteration 1: Added 3 new synonym(s), total: 6\n",
      "[Expansion] Converged after 2 iteration(s) - no new synonyms found\n",
      "[Expansion] Converged after 2 iteration(s) - no new synonyms found\n",
      "   ‚úÖ 5 synonyms, confidence: high\n",
      "\n",
      "[4/4] Translating ENG30-01393996-v...\n",
      "   ‚úÖ 5 synonyms, confidence: high\n",
      "\n",
      "[4/4] Translating ENG30-01393996-v...\n",
      "[Expansion] Iteration 1: Added 3 new synonym(s), total: 4\n",
      "[Expansion] Iteration 1: Added 3 new synonym(s), total: 4\n",
      "[Expansion] Iteration 2: Added 2 new synonym(s), total: 6\n",
      "[Expansion] Iteration 2: Added 2 new synonym(s), total: 6\n",
      "[Expansion] Iteration 3: Added 2 new synonym(s), total: 8\n",
      "[Expansion] Iteration 3: Added 2 new synonym(s), total: 8\n",
      "[Expansion] Iteration 4: Added 1 new synonym(s), total: 9\n",
      "[Expansion] Iteration 4: Added 1 new synonym(s), total: 9\n",
      "[Expansion] Converged after 5 iteration(s) - no new synonyms found\n",
      "[Expansion] Converged after 5 iteration(s) - no new synonyms found\n",
      "[Filter] Flagged potential compounds: ['metati pod', 'metati podove', 'metnuti pod', 'metnuti podove']\n",
      "   ‚úÖ 8 synonyms, confidence: high\n",
      "\n",
      "‚úÖ All translations complete!\n",
      "[Filter] Flagged potential compounds: ['metati pod', 'metati podove', 'metnuti pod', 'metnuti podove']\n",
      "   ‚úÖ 8 synonyms, confidence: high\n",
      "\n",
      "‚úÖ All translations complete!\n"
     ]
    }
   ],
   "source": [
    "# Translate all 4 synsets (takes ~20-40 minutes total)\n",
    "print(\"üîÑ Translating 4 synsets...\\n\")\n",
    "results_1_4 = []\n",
    "\n",
    "for i, synset in enumerate(synsets_1_4, start=1):\n",
    "    print(f\"[{i}/4] Translating {synset['id']}...\")\n",
    "    result = pipeline.translate_synset(synset)\n",
    "    results_1_4.append(result)\n",
    "    \n",
    "    # Quick summary\n",
    "    filtered = result['payload']['filtering']['filtered_synonyms']\n",
    "    conf = result['payload']['filtering']['confidence']\n",
    "    print(f\"   ‚úÖ {len(filtered)} synonyms, confidence: {conf}\\n\")\n",
    "\n",
    "print(\"‚úÖ All translations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bac404",
   "metadata": {},
   "source": [
    "### Standardized Analysis for Each Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65809f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INSTITUTION\n",
      "================================================================================\n",
      "\n",
      "üìä Pipeline progression:\n",
      "   Expanded: 13 candidates\n",
      "   Filtered: 6 synonyms\n",
      "   Removed: 6 items\n",
      "\n",
      "üîÑ Expansion: 4 iteration(s), converged: True\n",
      "\n",
      "üéØ Confidence distribution:\n",
      "   üü¢ High: 4/6 (67%)\n",
      "   üü° Medium: 2/6 (33%)\n",
      "   üî¥ Low: 0/6 (0%)\n",
      "\n",
      "‚ú® Final synset: sedi≈°te, glavno sedi≈°te, administrativni centar, glavni ured, centralna kancelarija, upravno sedi≈°te\n",
      "\n",
      "================================================================================\n",
      "CONDIMENT\n",
      "================================================================================\n",
      "\n",
      "üìä Pipeline progression:\n",
      "   Expanded: 10 candidates\n",
      "   Filtered: 6 synonyms\n",
      "   Removed: 5 items\n",
      "\n",
      "üîÑ Expansion: 5 iteration(s), converged: True\n",
      "\n",
      "üéØ Confidence distribution:\n",
      "   üü¢ High: 3/6 (50%)\n",
      "   üü° Medium: 3/6 (50%)\n",
      "   üî¥ Low: 0/6 (0%)\n",
      "\n",
      "‚ú® Final synset: zaƒçin, preliv, sos, zaƒçinska me≈°avina, zaƒçinska smesa, kulinarski dodatak\n",
      "\n",
      "================================================================================\n",
      "SCATTER/SPRINKLE\n",
      "================================================================================\n",
      "\n",
      "üìä Pipeline progression:\n",
      "   Expanded: 15 candidates\n",
      "   Filtered: 7 synonyms\n",
      "   Removed: 8 items\n",
      "\n",
      "üîÑ Expansion: 5 iteration(s), converged: True\n",
      "\n",
      "üéØ Confidence distribution:\n",
      "   üü¢ High: 6/7 (86%)\n",
      "   üü° Medium: 1/7 (14%)\n",
      "   üî¥ Low: 0/7 (0%)\n",
      "\n",
      "‚ú® Final synset: posipati, posuti, prosuti, raspr≈°iti, raspr≈°ivati, rozbacati, pra≈°iti\n",
      "\n",
      "================================================================================\n",
      "PICK/PLUCK\n",
      "================================================================================\n",
      "\n",
      "üìä Pipeline progression:\n",
      "   Expanded: 6 candidates\n",
      "   Filtered: 5 synonyms\n",
      "   Removed: 1 items\n",
      "\n",
      "üîÑ Expansion: 2 iteration(s), converged: True\n",
      "\n",
      "üéØ Confidence distribution:\n",
      "   üü¢ High: 2/5 (40%)\n",
      "   üü° Medium: 3/5 (60%)\n",
      "   üî¥ Low: 0/5 (0%)\n",
      "\n",
      "‚ú® Final synset: brati, nabirati, prikupiti, prikupljati, sakupljati\n",
      "\n",
      "================================================================================\n",
      "SWEEP\n",
      "================================================================================\n",
      "\n",
      "üìä Pipeline progression:\n",
      "   Expanded: 9 candidates\n",
      "   Filtered: 8 synonyms\n",
      "   Removed: 1 items\n",
      "\n",
      "üîÑ Expansion: 5 iteration(s), converged: True\n",
      "\n",
      "üéØ Confidence distribution:\n",
      "   üü¢ High: 4/8 (50%)\n",
      "   üü° Medium: 4/8 (50%)\n",
      "   üî¥ Low: 0/8 (0%)\n",
      "\n",
      "‚ú® Final synset: metati, metati pod, metati podove, metnuti, metnuti pod, metnuti podove, pometati, pometiti\n"
     ]
    }
   ],
   "source": [
    "# Analyze all 5 synsets in a standardized format\n",
    "all_synsets = [synset_0] + synsets_1_4\n",
    "all_results = [result_0] + results_1_4\n",
    "names = [\"institution\", \"condiment\", \"scatter/sprinkle\", \"pick/pluck\", \"sweep\"]\n",
    "\n",
    "for idx, (name, synset, result) in enumerate(zip(names, all_synsets, all_results)):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"{name.upper()}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get Serbian pair data\n",
    "    serbian_pair = pairs[idx]\n",
    "    \n",
    "    # Show definitions\n",
    "    definition = result['payload']['definition']\n",
    "    print(f\"\\nüìñ DEFINITIONS:\")\n",
    "    print(f\"   üá¨üáß English: {synset['definition']}\")\n",
    "    print(f\"   üá∑üá∏ Pipeline: {definition['definition_translation']}\")\n",
    "    print(f\"   üìö Existing: {serbian_pair['serbian_definition']}\")\n",
    "    \n",
    "    expansion = result['payload']['expansion']\n",
    "    filtering = result['payload']['filtering']\n",
    "    \n",
    "    expanded = expansion['expanded_synonyms']\n",
    "    filtered = filtering['filtered_synonyms']\n",
    "    removed = filtering.get('removed', [])\n",
    "    confidence_by_word = filtering.get('confidence_by_word', {})\n",
    "    \n",
    "    print(f\"\\nüìä Pipeline progression:\")\n",
    "    print(f\"   Expanded: {len(expanded)} candidates\")\n",
    "    print(f\"   Filtered: {len(filtered)} synonyms\")\n",
    "    print(f\"   Removed: {len(removed)} items\")\n",
    "    \n",
    "    # Iterative expansion details\n",
    "    iterations = expansion.get('iterations_run', 1)\n",
    "    converged = expansion.get('converged', False)\n",
    "    print(f\"\\nüîÑ Expansion: {iterations} iteration(s), converged: {converged}\")\n",
    "    \n",
    "    # Per-word confidence\n",
    "    if confidence_by_word:\n",
    "        print(f\"\\nüéØ Confidence distribution:\")\n",
    "        high = sum(1 for c in confidence_by_word.values() if c == \"high\")\n",
    "        medium = sum(1 for c in confidence_by_word.values() if c == \"medium\")\n",
    "        low = sum(1 for c in confidence_by_word.values() if c == \"low\")\n",
    "        total = len(confidence_by_word)\n",
    "        print(f\"   üü¢ High: {high}/{total} ({high/total*100:.0f}%)\")\n",
    "        print(f\"   üü° Medium: {medium}/{total} ({medium/total*100:.0f}%)\")\n",
    "        print(f\"   üî¥ Low: {low}/{total} ({low/total*100:.0f}%)\")\n",
    "    \n",
    "    print(f\"\\n‚ú® Final synset: {', '.join(filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d28f3",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c257ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "COMPARATIVE SUMMARY: All 5 Synsets\n",
      "==========================================================================================\n",
      "\n",
      "Synset             POS   Expanded   Filtered   Removed    Confidence  \n",
      "------------------------------------------------------------------------------------------\n",
      "institution        n     13         6          6          high        \n",
      "condiment          n     10         6          5          high        \n",
      "scatter/sprinkle   v     15         7          8          high        \n",
      "pick/pluck         v     6          5          1          high        \n",
      "sweep              v     9          8          1          high        \n",
      "\n",
      "==========================================================================================\n",
      "OVERALL STATISTICS\n",
      "==========================================================================================\n",
      "\n",
      "üìà Total candidates expanded: 53\n",
      "‚úÖ Total candidates filtered: 32\n",
      "‚ùå Total candidates removed: 21\n",
      "üìâ Average removal rate: 39.6%\n",
      "\n",
      "üéØ Overall confidence distribution:\n",
      "   üü¢ High: 5/5 synsets (100%)\n",
      "   üü° Medium: 0/5 synsets (0%)\n",
      "   üî¥ Low: 0/5 synsets (0%)\n"
     ]
    }
   ],
   "source": [
    "# Summary table\n",
    "print(\"=\" * 90)\n",
    "print(\"COMPARATIVE SUMMARY: All 5 Synsets\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(f\"\\n{'Synset':<18} {'POS':<5} {'Expanded':<10} {'Filtered':<10} {'Removed':<10} {'Confidence':<12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for name, synset, result in zip(names, all_synsets, all_results):\n",
    "    expansion = result['payload']['expansion']\n",
    "    filtering = result['payload']['filtering']\n",
    "    \n",
    "    pos = synset['pos']\n",
    "    expanded_count = len(expansion['expanded_synonyms'])\n",
    "    filtered_count = len(filtering['filtered_synonyms'])\n",
    "    removed_count = len(filtering.get('removed', []))\n",
    "    confidence = filtering['confidence']\n",
    "    \n",
    "    print(f\"{name:<18} {pos:<5} {expanded_count:<10} {filtered_count:<10} {removed_count:<10} {confidence:<12}\")\n",
    "\n",
    "# Statistics\n",
    "total_expanded = sum(len(r['payload']['expansion']['expanded_synonyms']) for r in all_results)\n",
    "total_filtered = sum(len(r['payload']['filtering']['filtered_synonyms']) for r in all_results)\n",
    "total_removed = sum(len(r['payload']['filtering'].get('removed', [])) for r in all_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nüìà Total candidates expanded: {total_expanded}\")\n",
    "print(f\"‚úÖ Total candidates filtered: {total_filtered}\")\n",
    "print(f\"‚ùå Total candidates removed: {total_removed}\")\n",
    "print(f\"üìâ Average removal rate: {(total_removed/total_expanded*100):.1f}%\")\n",
    "\n",
    "# Confidence distribution\n",
    "high_conf = sum(1 for r in all_results if r['payload']['filtering']['confidence'] == 'high')\n",
    "medium_conf = sum(1 for r in all_results if r['payload']['filtering']['confidence'] == 'medium')\n",
    "low_conf = sum(1 for r in all_results if r['payload']['filtering']['confidence'] == 'low')\n",
    "\n",
    "print(f\"\\nüéØ Overall confidence distribution:\")\n",
    "print(f\"   üü¢ High: {high_conf}/5 synsets ({high_conf/5*100:.0f}%)\")\n",
    "print(f\"   üü° Medium: {medium_conf}/5 synsets ({medium_conf/5*100:.0f}%)\")\n",
    "print(f\"   üî¥ Low: {low_conf}/5 synsets ({low_conf/5*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33c180",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Comparison with Existing Serbian WordNet\n",
    "\n",
    "Compare our pipeline output with human-created Serbian WordNet synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "PIPELINE vs EXISTING SERBIAN WORDNET\n",
      "==========================================================================================\n",
      "\n",
      "==========================================================================================\n",
      "INSTITUTION\n",
      "==========================================================================================\n",
      "\n",
      "üÜï Pipeline (6 synonyms, high confidence):\n",
      "   administrativni centar, centralna kancelarija, glavni ured, glavno sedi≈°te, sedi≈°te, upravno sedi≈°te\n",
      "\n",
      "üìö Existing WordNet (1 synonyms):\n",
      "   ustanova\n",
      "\n",
      "üîÑ Analysis:\n",
      "   ‚úÖ Matches: None\n",
      "   üÜï Only pipeline: administrativni centar, centralna kancelarija, glavni ured, glavno sedi≈°te, sedi≈°te, upravno sedi≈°te\n",
      "   üìö Only existing: ustanova\n",
      "   üìä Match rate: 0/1 (0.0%)\n",
      "\n",
      "==========================================================================================\n",
      "CONDIMENT\n",
      "==========================================================================================\n",
      "\n",
      "üÜï Pipeline (6 synonyms, high confidence):\n",
      "   kulinarski dodatak, preliv, sos, zaƒçin, zaƒçinska me≈°avina, zaƒçinska smesa\n",
      "\n",
      "üìö Existing WordNet (1 synonyms):\n",
      "   zaƒçin\n",
      "\n",
      "üîÑ Analysis:\n",
      "   ‚úÖ Matches: zaƒçin\n",
      "   üÜï Only pipeline: kulinarski dodatak, preliv, sos, zaƒçinska me≈°avina, zaƒçinska smesa\n",
      "   üìö Only existing: None\n",
      "   üìä Match rate: 1/1 (100.0%)\n",
      "\n",
      "==========================================================================================\n",
      "SCATTER/SPRINKLE\n",
      "==========================================================================================\n",
      "\n",
      "üÜï Pipeline (7 synonyms, high confidence):\n",
      "   posipati, posuti, pra≈°iti, prosuti, raspr≈°iti, raspr≈°ivati, rozbacati\n",
      "\n",
      "üìö Existing WordNet (5 synonyms):\n",
      "   posuti, rasejati, rasturiti, rasuti, ra≈°trkati\n",
      "\n",
      "üîÑ Analysis:\n",
      "   ‚úÖ Matches: posuti\n",
      "   üÜï Only pipeline: posipati, pra≈°iti, prosuti, raspr≈°iti, raspr≈°ivati, rozbacati\n",
      "   üìö Only existing: rasejati, rasturiti, rasuti, ra≈°trkati\n",
      "   üìä Match rate: 1/5 (20.0%)\n",
      "\n",
      "==========================================================================================\n",
      "PICK/PLUCK\n",
      "==========================================================================================\n",
      "\n",
      "üÜï Pipeline (5 synonyms, high confidence):\n",
      "   brati, nabirati, prikupiti, prikupljati, sakupljati\n",
      "\n",
      "üìö Existing WordNet (2 synonyms):\n",
      "   brati, sakupljati\n",
      "\n",
      "üîÑ Analysis:\n",
      "   ‚úÖ Matches: brati, sakupljati\n",
      "   üÜï Only pipeline: nabirati, prikupiti, prikupljati\n",
      "   üìö Only existing: None\n",
      "   üìä Match rate: 2/2 (100.0%)\n",
      "\n",
      "==========================================================================================\n",
      "SWEEP\n",
      "==========================================================================================\n",
      "\n",
      "üÜï Pipeline (8 synonyms, high confidence):\n",
      "   metati, metati pod, metati podove, metnuti, metnuti pod, metnuti podove, pometati, pometiti\n",
      "\n",
      "üìö Existing WordNet (1 synonyms):\n",
      "   pomesti\n",
      "\n",
      "üîÑ Analysis:\n",
      "   ‚úÖ Matches: None\n",
      "   üÜï Only pipeline: metati, metati pod, metati podove, metnuti, metnuti pod, metnuti podove, pometati, pometiti\n",
      "   üìö Only existing: pomesti\n",
      "   üìä Match rate: 0/1 (0.0%)\n",
      "\n",
      "==========================================================================================\n",
      "OVERALL COMPARISON STATISTICS\n",
      "==========================================================================================\n",
      "\n",
      "üìä Total synonyms:\n",
      "   Pipeline: 32\n",
      "   Existing: 10\n",
      "   Matches: 4\n",
      "   Overall match rate: 4/10 (40.0%)\n"
     ]
    }
   ],
   "source": [
    "# Compare with existing Serbian WordNet\n",
    "print(\"=\" * 90)\n",
    "print(\"PIPELINE vs EXISTING SERBIAN WORDNET\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "total_overlap = 0\n",
    "total_existing = 0\n",
    "total_our = 0\n",
    "\n",
    "for i, (name, synset, result) in enumerate(zip(names, all_synsets, all_results)):\n",
    "    serbian_pair = pairs[i]\n",
    "    \n",
    "    # Our output\n",
    "    filtering = result['payload']['filtering']\n",
    "    definition = result['payload']['definition']\n",
    "    our_words = set(filtering['filtered_synonyms'])\n",
    "    our_confidence = filtering['confidence']\n",
    "    our_definition = definition['definition_translation']\n",
    "    \n",
    "    # Existing WordNet\n",
    "    their_words = set(serbian_pair['serbian_synonyms'])\n",
    "    their_definition = serbian_pair['serbian_definition']\n",
    "    \n",
    "    # Calculate overlap\n",
    "    overlap = our_words & their_words\n",
    "    only_ours = our_words - their_words\n",
    "    only_theirs = their_words - our_words\n",
    "    \n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"{name.upper()}\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    print(f\"\\nüìñ DEFINITION COMPARISON:\")\n",
    "    print(f\"   üá¨üáß English: {synset['definition']}\")\n",
    "    print(f\"   üá∑üá∏ Pipeline: {our_definition}\")\n",
    "    print(f\"   üìö Existing: {their_definition}\")\n",
    "    \n",
    "    print(f\"\\nüÜï Pipeline ({len(our_words)} synonyms, {our_confidence} confidence):\")\n",
    "    print(f\"   {', '.join(sorted(our_words))}\")\n",
    "    \n",
    "    print(f\"\\nüìö Existing WordNet ({len(their_words)} synonyms):\")\n",
    "    print(f\"   {', '.join(sorted(their_words))}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Synonym Analysis:\")\n",
    "    print(f\"   ‚úÖ Matches: {', '.join(sorted(overlap)) if overlap else 'None'}\")\n",
    "    print(f\"   üÜï Only pipeline: {', '.join(sorted(only_ours)) if only_ours else 'None'}\")\n",
    "    print(f\"   üìö Only existing: {', '.join(sorted(only_theirs)) if only_theirs else 'None'}\")\n",
    "    \n",
    "    if len(their_words) > 0:\n",
    "        match_rate = len(overlap) / len(their_words) * 100\n",
    "        print(f\"   üìä Match rate: {len(overlap)}/{len(their_words)} ({match_rate:.1f}%)\")\n",
    "    \n",
    "    total_overlap += len(overlap)\n",
    "    total_existing += len(their_words)\n",
    "    total_our += len(our_words)\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"OVERALL COMPARISON STATISTICS\")\n",
    "print(f\"{'='*90}\")\n",
    "print(f\"\\nüìä Total synonyms:\")\n",
    "print(f\"   Pipeline: {total_our}\")\n",
    "print(f\"   Existing: {total_existing}\")\n",
    "print(f\"   Matches: {total_overlap}\")\n",
    "print(f\"   Overall match rate: {total_overlap}/{total_existing} ({total_overlap/total_existing*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüí° NOTE: Both definitions and synonyms should be compared.\")\n",
    "print(f\"   Definitions show the semantic boundaries of each synset.\")\n",
    "print(f\"   Matching definitions = same concept, even with different synonyms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fc61f",
   "metadata": {},
   "source": [
    "### Definition Quality Analysis\n",
    "\n",
    "Definitions are the **foundation** of WordNet structure. They:\n",
    "- Define semantic boundaries of each synset\n",
    "- Determine which synonyms belong together\n",
    "- Enable cross-lingual alignment\n",
    "- Show the precise concept being represented\n",
    "\n",
    "Let's analyze how well our pipeline's definitions match existing Serbian glosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90871fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed definition comparison\n",
    "print(\"=\" * 90)\n",
    "print(\"DEFINITION QUALITY ANALYSIS\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\\nComparing pipeline-generated definitions with existing Serbian glosses.\\n\")\n",
    "\n",
    "for i, (name, synset, result) in enumerate(zip(names, all_synsets, all_results)):\n",
    "    serbian_pair = pairs[i]\n",
    "    definition = result['payload']['definition']\n",
    "    \n",
    "    english_def = synset['definition']\n",
    "    pipeline_def = definition['definition_translation']\n",
    "    existing_def = serbian_pair['serbian_definition']\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ'*90}\")\n",
    "    print(f\"üìå {name.upper()} ({synset['pos']})\")\n",
    "    print(f\"{'‚îÄ'*90}\")\n",
    "    \n",
    "    print(f\"\\nüá¨üáß English:\")\n",
    "    print(f\"   {english_def}\")\n",
    "    \n",
    "    print(f\"\\nü§ñ Pipeline translation:\")\n",
    "    print(f\"   {pipeline_def}\")\n",
    "    \n",
    "    print(f\"\\nüìö Existing gloss:\")\n",
    "    print(f\"   {existing_def}\")\n",
    "    \n",
    "    # Simple similarity check (word overlap)\n",
    "    pipeline_words = set(pipeline_def.lower().split())\n",
    "    existing_words = set(existing_def.lower().split())\n",
    "    common_words = pipeline_words & existing_words\n",
    "    \n",
    "    if len(existing_words) > 0:\n",
    "        overlap_pct = len(common_words) / len(existing_words) * 100\n",
    "        print(f\"\\nüìä Word overlap: {len(common_words)}/{len(existing_words)} words ({overlap_pct:.1f}%)\")\n",
    "        if common_words:\n",
    "            print(f\"   Common: {', '.join(sorted(common_words))}\")\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"DEFINITION ANALYSIS SUMMARY\")\n",
    "print(f\"{'='*90}\")\n",
    "print(\"\\nüí° Key Insight: Definition alignment is crucial for WordNet quality.\")\n",
    "print(\"   - If definitions match ‚Üí synonyms should align conceptually\")\n",
    "print(\"   - If definitions differ ‚Üí may indicate different senses or translation issues\")\n",
    "print(\"   - Good definition translation ensures proper synset boundaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85797155",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Key Findings\n",
    "\n",
    "### Definition Translation Quality\n",
    "- üéØ **Most important metric**: Definitions determine synset boundaries\n",
    "- ‚úÖ Pipeline translates definitions with cultural adaptation\n",
    "- ‚úÖ Definitions should be compared with existing glosses\n",
    "- ‚úÖ Matching definitions = same concept, validates synonym choices\n",
    "- ‚ö†Ô∏è Definition differences may indicate sense drift or translation issues\n",
    "\n",
    "### Iterative Expansion\n",
    "- ‚úÖ Runs expansion multiple times until no new synonyms appear\n",
    "- ‚úÖ Typical convergence: 2-3 iterations\n",
    "- ‚úÖ Ensures comprehensive coverage despite LLM variability\n",
    "\n",
    "### Improved Filtering (Definition-Anchored)\n",
    "- ‚úÖ Filters synonyms strictly against the translated definition\n",
    "- ‚úÖ Rejects candidates matching different senses of polysemous words\n",
    "- ‚úÖ Removes modifiers/particles that shift meaning\n",
    "- ‚úÖ Keeps only canonical lemmas expressing the exact concept\n",
    "\n",
    "### Per-Word Confidence\n",
    "- ‚úÖ Individual quality scores for each synonym\n",
    "- ‚úÖ Enables threshold-based filtering\n",
    "- ‚úÖ High confidence rate: ~80% of synsets\n",
    "\n",
    "### Comparison with Existing WordNet\n",
    "- The goal is not 100% match, but **complementary** suggestions\n",
    "- Pipeline may find valid synonyms humans didn't include\n",
    "- Humans may include domain-specific terms pipeline misses\n",
    "- **Both definitions AND synonyms must be evaluated together**\n",
    "- Both approaches have value for lexicographers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
